{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:07:41.161712Z",
     "start_time": "2025-11-28T08:07:41.158812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from openai import OpenAI\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "# client = OpenAI()\n",
    "#\n",
    "# response = client.responses.create(\n",
    "#     model=\"gpt-5-nano\",\n",
    "#     input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    "# )\n",
    "#\n",
    "# print(response.output_text)"
   ],
   "id": "c48cdf1d942d9ee6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:11:48.338510Z",
     "start_time": "2025-11-28T09:11:37.914312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "client = genai.Client()\n",
    "text = \"Machine Learning is a field of artificial intelligence that enables computers to learn from data and make predictions\"\n",
    "prompt = f\"\"\"Explain the key concepts of the text delimited by triple backticks in simple terms ```{text}```\"\"\"\n",
    "\n",
    "print(prompt, '\\n')\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=prompt\n",
    ")\n",
    "print(response.text)\n"
   ],
   "id": "8e3de740ed1db32b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the key concepts of the text delimited by triple backticks in simple terms ```Machine Learning is a field of artificial intelligence that enables computers to learn from data and make predictions``` \n",
      "\n",
      "Okay, let's break down that sentence:\n",
      "\n",
      "1.  **Machine Learning:** This is the main topic. It's a method or a way of doing things.\n",
      "2.  **Artificial Intelligence (AI):** This is the bigger, overall goal â€“ making computers smart, like humans. Machine Learning is a *part* of this bigger goal.\n",
      "3.  **Computers learn from data:** Instead of being told every single rule, the computer looks at lots of examples and information (\"data\"). From these examples, it figures out patterns and rules on its own.\n",
      "4.  **Make predictions:** Once the computer has learned from the data, it can then use that knowledge to guess what might happen next, or identify something it hasn't seen before.\n",
      "\n",
      "**In simple terms:**\n",
      "\n",
      "Machine Learning is a way to make computers smart (which is called Artificial Intelligence). It lets computers teach themselves by looking at lots of information, and then use what they've learned to make educated guesses about new things.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:07:52.744123Z",
     "start_time": "2025-11-28T08:07:49.573794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents='Translate the following English sentence into French: \"The weather is nice today\"'\n",
    ")\n",
    "print(response.text)"
   ],
   "id": "e6ebb617d529d4de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common and natural way to say \"The weather is nice today\" in French is:\n",
      "\n",
      "**Il fait beau aujourd'hui.**\n",
      "\n",
      "*   \"Il fait beau\" is a standard impersonal expression meaning \"the weather is nice/beautiful.\"\n",
      "*   \"aujourd'hui\" means \"today.\"\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Zero Shot Prompting: No Examples",
   "id": "8dc0dac76890e89f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:11:50.460707Z",
     "start_time": "2025-11-28T09:11:48.369163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config= genai.types.GenerateContentConfig(\n",
    "        # system_instruction=mr_chris_persona,\n",
    "        temperature=0.\n",
    "    )\n",
    ")\n",
    "response = chat.send_message('Translate the following English sentence into French: \"The weather is nice today')\n",
    "\n",
    "print(response.text)"
   ],
   "id": "b84fd3ee1e61258",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Il fait beau aujourd'hui.**\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### One Shot Prompting: Single Example in prompt",
   "id": "5eddafef893f68b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:07:55.645738Z",
     "start_time": "2025-11-28T08:07:54.800939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"Detect the Language of the following sentences:\n",
    "text: \"A plus tard\" -> language: \"French\"\n",
    "Now detect:\n",
    "text: \"Gracias\"\n",
    "\"\"\"\n",
    "\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config= genai.types.GenerateContentConfig(\n",
    "        temperature=0.\n",
    "    )\n",
    ")\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "print(response.text)"
   ],
   "id": "ff42184d5b2182eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: \"Spanish\"\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Few-shot prompting",
   "id": "e239ed8a8c0a9121"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:07:56.209798Z",
     "start_time": "2025-11-28T08:07:55.677261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt =\"\"\"Determine the sentiment of the following sentences:\n",
    "text: \"I love this product! It works perfectly.\" -> classification: Positive\n",
    "text: \"The service was terrible. I'm very disappointed.\" -> Classification: Negative\n",
    "text: \"The food was okay, nothing special.\" -> Classification: Neutral\n",
    "Now analyze this sentence:\n",
    "\"The movie was amazing, I enjoyed every moment of it!\"\n",
    "\"\"\"\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "print(response.text)"
   ],
   "id": "a6cd881d18e369b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Positive\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Multi-step prompting",
   "id": "f28f83c2bed4faa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:07:57.520784Z",
     "start_time": "2025-11-28T08:07:56.233852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Marie Curie discovered radium 1898\"\n",
    "prompt = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
    "Step 1: Identify the key entities in the sentence.\n",
    "Step 2:\n",
    "Classify each entity as a person, event, or object.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "print(response.text)"
   ],
   "id": "23169046a2f0dbaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify the key entities in the sentence.\n",
      "- Marie Curie\n",
      "- radium\n",
      "- 1898\n",
      "\n",
      "Step 2: Classify each entity as a person, event, or object.\n",
      "- Marie Curie: Person\n",
      "- radium: Object\n",
      "- 1898: Event\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Chain of thought prompting",
   "id": "731ea5a1f2b9337e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:07:58.645927Z",
     "start_time": "2025-11-28T08:07:57.563094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"John has 3 apples. He buys 5 more and gives away 2. How many apples does he have now? Think step by step.\"\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "print(response.text)"
   ],
   "id": "e52fa469a081b8b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's how to solve it step-by-step:\n",
      "\n",
      "1.  **Start with:** John has 3 apples.\n",
      "2.  **Buys more:** He buys 5 more, so 3 + 5 = 8 apples.\n",
      "3.  **Gives away:** He gives away 2, so 8 - 2 = 6 apples.\n",
      "\n",
      "John has 6 apples now.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Self Consistency Prompting",
   "id": "18e70ce2d85b6638"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:08:05.271637Z",
     "start_time": "2025-11-28T08:07:58.674448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruction = \"Imagine three completely independent experts who reason differently are answering this question. The final answer is obtained by majority vote. The question is: \"\n",
    "question = \"A bookstore has 20 books ona shelf. A customer buys 5 books. Then, the store restocks with double the number of books bought. After that, another customer buys 8 books. How many books are left on the shelf?\"\n",
    "prompt = instruction + question\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "print(response.text)"
   ],
   "id": "97231c86626a3ac5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's how three independent experts might reason:\n",
      "\n",
      "**Expert 1: The Sequential Tracker**\n",
      "\n",
      "\"I'll follow the books on the shelf step-by-step, updating the total after each event.\"\n",
      "\n",
      "1.  **Start:** The shelf has 20 books.\n",
      "2.  **First purchase:** A customer buys 5 books.\n",
      "    *   Current books: 20 - 5 = 15 books.\n",
      "3.  **Restock:** The store restocks with double the number of books bought (2 * 5 = 10 books).\n",
      "    *   Current books: 15 + 10 = 25 books.\n",
      "4.  **Second purchase:** Another customer buys 8 books.\n",
      "    *   Current books: 25 - 8 = 17 books.\n",
      "\n",
      "*Expert 1's Answer: 17 books*\n",
      "\n",
      "---\n",
      "\n",
      "**Expert 2: The Transaction Analyst**\n",
      "\n",
      "\"I'll view this as a series of transactions affecting the initial quantity, calculating the net effect.\"\n",
      "\n",
      "1.  **Initial state:** 20 books.\n",
      "2.  **Transaction 1 (Purchase):** - 5 books.\n",
      "3.  **Transaction 2 (Restock):** The number bought was 5, so double that is 10 books. This is an addition: + 10 books.\n",
      "4.  **Transaction 3 (Purchase):** - 8 books.\n",
      "\n",
      "Now, let's apply these changes to the initial amount:\n",
      "20 (initial) - 5 (bought) + 10 (restocked) - 8 (bought)\n",
      "= 15 + 10 - 8\n",
      "= 25 - 8\n",
      "= 17 books\n",
      "\n",
      "*Expert 2's Answer: 17 books*\n",
      "\n",
      "---\n",
      "\n",
      "**Expert 3: The Net Change Calculator**\n",
      "\n",
      "\"I'll determine the total change in books from all operations and then apply it to the starting number.\"\n",
      "\n",
      "1.  **Books removed:**\n",
      "    *   First customer: 5 books\n",
      "    *   Second customer: 8 books\n",
      "    *   Total removed: 5 + 8 = 13 books\n",
      "2.  **Books added:**\n",
      "    *   Restock: Double the number bought by the first customer (2 * 5) = 10 books.\n",
      "3.  **Net change in books:** Books added - Books removed = 10 - 13 = -3 books.\n",
      "    *   This means there are 3 fewer books than when we started.\n",
      "4.  **Final number of books:** Initial books + Net change = 20 + (-3) = 17 books.\n",
      "\n",
      "*Expert 3's Answer: 17 books*\n",
      "\n",
      "---\n",
      "\n",
      "**Majority Vote:**\n",
      "\n",
      "*   Expert 1: 17 books\n",
      "*   Expert 2: 17 books\n",
      "*   Expert 3: 17 books\n",
      "\n",
      "All three experts agree.\n",
      "\n",
      "**Final Answer:**\n",
      "There are **17** books left on the shelf.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T08:38:18.447604Z",
     "start_time": "2025-11-28T08:37:22.258954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"Act as an experienced hiring manager. Ask me five interview questions one by one. After I respond, provide constructive feedback on my answer, including strengths and areas for improvement. If my response is incomplete, guide me toward a better answer.\"\n",
    "user_prompt = \"I'm preparing for a Data Scientist interview. Can you ask me fine five questions and evaluate my responses?\"\n",
    "\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config= genai.types.GenerateContentConfig(\n",
    "        system_instruction = system_prompt,\n",
    "        temperature=0.\n",
    "    )\n",
    ")\n",
    "response = chat.send_message(user_prompt)\n",
    "print(response.text)\n",
    "while True:\n",
    "    print(f\"User is Speaking \\n\")\n",
    "    user_input = input(\"\\nYou: \")\n",
    "    response = chat.send_message(user_input)\n",
    "    print(f\"Gemini is Speaking: \\n{response.text}\")\n",
    "\n",
    "    break\n",
    "print(response.text)"
   ],
   "id": "88327492c830826b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent! It's great you're proactively preparing. As an experienced hiring manager, I'm here to help you sharpen your responses.\n",
      "\n",
      "Let's start with our first question. Take your time, and remember to be concise yet comprehensive.\n",
      "\n",
      "**Question 1:** \"Tell me about yourself and what led you to pursue a career in Data Science.\"\n",
      "User is Speaking \n",
      "\n",
      "Gemini is Speaking: \n",
      "Understood. While \"Tell me about yourself\" is a very common opening, we can certainly move on.\n",
      "\n",
      "Let's jump right into a more technical scenario.\n",
      "\n",
      "**Question 2:** \"Describe a challenging data science project you've worked on. What was the problem, what was your approach, what were the key challenges, and what was the outcome?\"\n",
      "User is Speaking \n",
      "\n",
      "Gemini is Speaking: \n",
      "Okay, I understand you'd like to skip these broader, more experience-based questions.\n",
      "\n",
      "As a hiring manager, I'd typically use questions like \"Tell me about yourself\" and \"Describe a challenging project\" to understand your communication style, your ability to structure a narrative, and to get a high-level overview of your experience and problem-solving skills before diving into specifics. They're often foundational for setting the stage.\n",
      "\n",
      "However, if you prefer, we can certainly move to a more specific, perhaps technical, question.\n",
      "\n",
      "Let's try this one. This is a common type of question to assess your understanding of core concepts.\n",
      "\n",
      "**Question 3:** \"Imagine you're building a classification model, and you notice a significant class imbalance in your dataset (e.g., 95% of observations belong to one class, and only 5% to the other). How would you approach this problem, and what metrics would you use to evaluate your model's performance?\"\n",
      "User is Speaking \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m     14\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUser is Speaking \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     user_input = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43mYou: \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m     response = chat.send_message(user_input)\n\u001B[32m     17\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mGemini is Speaking: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mresponse.text\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\GEN-AI\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1275\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1273\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1274\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1275\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1276\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1277\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1278\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1279\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1280\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\GEN-AI\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1320\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1317\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1318\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1319\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1320\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1321\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1322\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:13:23.578743Z",
     "start_time": "2025-11-28T09:13:23.573520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "user_profile = {\n",
    "\"name\": \"Zara\",\n",
    "\"interest\": \"coding\",\n",
    "\"goal\": \"learn AI\",\n",
    "\"tone\": \"friendly\",\n",
    "\"length\": \"short\"\n",
    "}\n",
    "prompt = f\"\"\"My name is {user_profile['name']}. I love {user_profile['interest']} and want to\n",
    "{user_profile['goal']}. Write a {user_profile['tone']} and {user_profile['length']} guide on how I can\n",
    "start.\"\"\"\n",
    "print(\"Generated Prompt: \\n\", prompt)"
   ],
   "id": "5d61417f3aed725f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt: \n",
      " My name is Zara. I love coding and want to\n",
      "learn AI. Write a friendly and short guide on how I can\n",
      "start.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:13:35.371785Z",
     "start_time": "2025-11-28T09:13:25.732462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config= genai.types.GenerateContentConfig(\n",
    "        # system_instruction = prompt,\n",
    "        temperature=0\n",
    "    )\n",
    ")\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "print(response.text)"
   ],
   "id": "a305dbbe489ec828",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Zara! That's fantastic! With your coding background, you're already in a great spot to dive into AI. Here's a friendly and short guide to get you started:\n",
      "\n",
      "1.  **Leverage Your Python Skills:** Python is the absolute go-to language for AI. If you're already comfortable with it, you're ahead of the game! If not, a quick refresher on Python fundamentals (especially data structures and functions) will be super helpful.\n",
      "\n",
      "2.  **Understand the Basics of Machine Learning (ML):** AI is a broad field, and Machine Learning is a core part of it. Start with introductory courses that cover:\n",
      "    *   **What ML is:** Teaching computers to learn from data without being explicitly programmed.\n",
      "    *   **Types of ML:** Supervised vs. Unsupervised Learning.\n",
      "    *   **Simple Algorithms:** Linear Regression (for predictions) and K-Nearest Neighbors (for classification) are great starting points.\n",
      "\n",
      "3.  **Online Resources are Your Best Friend:**\n",
      "    *   **Coursera/edX:** Look for \"Introduction to Machine Learning\" courses (Andrew Ng's is a classic).\n",
      "    *   **freeCodeCamp/Kaggle:** Offer great practical tutorials and coding challenges.\n",
      "    *   **YouTube:** Channels like \"StatQuest with Josh Starmer\" explain concepts brilliantly.\n",
      "\n",
      "4.  **Get Hands-On with Libraries:** As you learn, you'll quickly get familiar with essential Python libraries:\n",
      "    *   **NumPy:** For numerical operations.\n",
      "    *   **Pandas:** For data manipulation and analysis.\n",
      "    *   **Scikit-learn:** The go-to library for implementing many ML algorithms easily.\n",
      "\n",
      "5.  **Start Small Projects:** The best way to learn is by doing!\n",
      "    *   Try to predict house prices based on features.\n",
      "    *   Classify different types of flowers from a dataset.\n",
      "    *   Build a simple spam detector.\n",
      "\n",
      "**Key takeaway:** Don't try to learn everything at once. Take it step by step, focus on understanding the core concepts, and most importantly, have fun building things!\n",
      "\n",
      "You've got this, Zara! Happy coding and welcome to the exciting world of AI!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:35:00.908509Z",
     "start_time": "2025-11-28T09:34:59.601012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"@LS_King: Yo why'd you blow up my car?! @ThugLife99: Cry about it #GetRekt\"\"\"\n",
    "prompt = f\"\"\"Analyze this GTA Online tweet fight:\n",
    "1. Who started it?\n",
    "2. Most toxic word?\n",
    "3. Suggested peace treaty (funny):\n",
    "4. let your responses be short and avoid use of asterisks for displaying texxt\n",
    "```{text}```\"\"\"\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "print(response.text)"
   ],
   "id": "46c50ba06974f169",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the analysis:\n",
      "\n",
      "1.  LS_King started the tweet fight.\n",
      "2.  GetRekt.\n",
      "3.  ThugLife99 must buy LS_King a new car, then they both do a friendly stunt race where the loser buys pizza.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:46:44.406835Z",
     "start_time": "2025-11-28T09:46:43.000033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Tesla is an electric vehicle company. Its stock price has increased by 20% in the last year. Apple is a technology company known for its iphones. Its stock price has increased by 15% in the last year. Amazon is an e-commerce and cloud computing giant. Its stock price has increased by 10% in the last year.\"\n",
    "prompt = f\"\"\"Convert the following information into a well formatted table format with columns for company, industry and stock performance:\n",
    "Text: ```{text}``` \"\"\"\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "print(response.text)"
   ],
   "id": "232853819369759e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Company | Industry                  | Stock Performance      |\n",
      "|---------|---------------------------|------------------------|\n",
      "| Tesla   | Electric Vehicle          | Increased by 20%       |\n",
      "| Apple   | Technology                | Increased by 15%       |\n",
      "| Amazon  | E-commerce and Cloud Computing | Increased by 10%       |\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:02:32.243178Z",
     "start_time": "2025-11-28T10:02:30.072323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Artificial Intelligence is transforming industries like healthcare, finance, and education by improving efficiency and decision making.\"\n",
    "prompt = f\"\"\"Format the response in a list:\n",
    "- Summarize the key industries AI is transforming.\n",
    "- Highlight its impact.\n",
    "Text: ```{text}```\n",
    "\n",
    "dont use asterisks\"\"\"\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "print(response.text)"
   ],
   "id": "269640fc3c147d35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Key Industries AI is Transforming:\n",
      "  - Healthcare\n",
      "  - Finance\n",
      "  - Education\n",
      "- Highlight its Impact:\n",
      "  - Improving efficiency\n",
      "  - Enhancing decision making\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:03:58.656943Z",
     "start_time": "2025-11-28T10:03:56.567389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"John is a data scientist with expertise in python and machine learning.\"\n",
    "prompt = f\"\"\"Extract key details from the text and return the output in JSON format.\n",
    "Text:\n",
    "```{text}```\n",
    "Output format:\n",
    "{{\n",
    "\"name\": \",\n",
    "\"profession\":\",\n",
    "\"skills\": []\n",
    "}}\"\"\"\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "print(response.text)"
   ],
   "id": "f0009972a6bca7a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\"name\": \"John\",\n",
      "\"profession\": \"data scientist\",\n",
      "\"skills\": [\"python\", \"machine learning\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:15:19.683124Z",
     "start_time": "2025-11-28T10:15:17.332754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Write a structured paragraph with clear headings and subheadings about the impact of a balanced diet on physical and mental health.\"\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "print(response.text)"
   ],
   "id": "81eed50d54e7632a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A balanced diet profoundly influences overall well-being, impacting both the body and mind significantly.\n",
      "\n",
      "**Physical Health Benefits**\n",
      "A well-rounded diet provides the necessary fuel for optimal bodily functions. This includes **Sustained Energy Levels**, as complex carbohydrates, healthy fats, and proteins ensure a steady release of energy throughout the day, preventing crashes and fatigue. Moreover, proper nutrition is crucial for **Disease Prevention**, strengthening the immune system, maintaining a healthy weight, and reducing the risk of chronic conditions such as heart disease, type 2 diabetes, and certain cancers.\n",
      "\n",
      "**Mental Well-being**\n",
      "Beyond the physical, a balanced diet plays a critical role in mental health. It supports **Mood Regulation** by providing essential nutrients that are precursors to neurotransmitters like serotonin and dopamine, which are vital for emotional stability and reducing symptoms of depression and anxiety. Furthermore, it enhances **Cognitive Function**, improving concentration, memory, and overall brain performance, as the brain requires a consistent supply of nutrients to operate effectively.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "387df72ce9abcb32"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üç∑ Red Wine Quality Prediction: A Machine Learning Approach\n",
    "\n",
    "In this notebook, we will build a machine learning model to predict the quality of red wine based on its chemical properties. We will follow a standard data science process:\n",
    "1.  **Data Loading and Exploration (EDA)**\n",
    "2.  **Feature Engineering and Preprocessing**\n",
    "3.  **Model Training**\n",
    "4.  **Model Evaluation**\n",
    "5.  **Model Saving** (for API deployment)\n",
    "\n",
    "The final output will be a simple binary classifier (Good/Bad), which is ideal for a simple API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Exploratory Data Analysis (EDA)\n",
    "\n",
    "First, we load the dataset and get a feel for its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset Head ---\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  alcohol  quality\n",
      "0            7.4              0.70         0.00             1.9      0.076                 11.0                  34.0   0.9978  3.51       0.56      9.4        5\n",
      "1            7.8              0.88         0.00             2.6      0.098                 25.0                  67.0   0.9968  3.20       0.68      9.8        5\n",
      "2            7.8              0.76         0.04             2.3      0.092                 15.0                  54.0   0.9970  3.26       0.65      9.8        5\n",
      "3           11.2              0.28         0.56             1.9      0.075                 17.0                  60.0   0.9980  3.16       0.58      9.8        6\n",
      "4            7.4              0.70         0.00             1.9      0.076                 11.0                  34.0   0.9978  3.51       0.56      9.4        5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib # Import joblib for saving the model\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/SamuelDasaolu/Practice_datasets/refs/heads/main/winequality-red.csv\"\n",
    "wine_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"--- Dataset Head ---\")\n",
    "print(wine_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the dataset's structure and check for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "\n",
      "--- Missing Values Check ---\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get information about the dataframe\n",
    "print(\"\\n--- Dataset Info ---\")\n",
    "wine_df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n--- Missing Values Check ---\")\n",
    "print(wine_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The data is clean. We have 1599 entries, all 11 features are numeric, and there are **no missing values**. This simplifies preprocessing.\n",
    "\n",
    "---\n",
    "#### Summary Statistics\n",
    "\n",
    "Let's look at the summary statistics to understand feature scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Descriptive Statistics ---\n",
      "       fixed acidity  volatile acidity  citric acid  residual sugar  ...        pH  sulphates     alcohol      quality\n",
      "count    1599.000000       1599.000000  1599.000000     1599.000000  ... 1599.000000  1599.000000  1599.000000  1599.000000\n",
      "mean        8.319637          0.527821     0.270976        2.538806  ...    3.311113     0.658149    10.422983     5.636023\n",
      "std         1.741096          0.179060     0.194801        1.409928  ...    0.154386     0.169507     1.065668     0.807569\n",
      "min         4.600000          0.120000     0.000000        0.900000  ...    2.740000     0.330000     8.400000     3.000000\n",
      "25%         7.100000          0.390000     0.090000        1.900000  ...    3.210000     0.550000     9.500000     5.000000\n",
      "50%         7.900000          0.520000     0.260000        2.200000  ...    3.310000     0.620000    10.200000     6.000000\n",
      "75%         9.200000          0.640000     0.420000        2.600000  ...    3.400000     0.730000    11.100000     6.000000\n",
      "max        15.900000          1.580000     1.000000       15.500000  ...    4.010000     2.000000    14.900000     8.000000\n",
      "\n",
      "[8 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get summary statistics\n",
    "print(\"\\n--- Descriptive Statistics ---\")\n",
    "print(wine_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The features are on very different scales (e.g., `total sulfur dioxide` has a mean of ~46, while `pH` has a mean of ~3.3). This indicates that **feature scaling** will be necessary.\n",
    "\n",
    "---\n",
    "#### Visualizing the Target Variable\n",
    "\n",
    "Let's see the distribution of our target variable, `quality`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quality_distribution.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA...AASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the target variable 'quality'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='quality', data=wine_df, palette=\"viridis\")\n",
    "plt.title('Distribution of Red Wine Quality')\n",
    "plt.xlabel('Quality Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('quality_distribution.png')\n",
    "print(\"Saved quality_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** This is a multi-class problem (ratings 3-8), but the classes are highly **imbalanced**. The vast majority of wines are rated 5 or 6.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering & Preprocessing\n",
    "\n",
    "**Goal:** Simplify the problem for a more robust and simple API.\n",
    "\n",
    "We will convert this into a **binary classification** problem:\n",
    "* **Bad (0):** Quality rating 6 or less.\n",
    "* **Good (1):** Quality rating 7 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- New Target Variable Distribution ---\n",
      "0    0.86429\n",
      "1    0.13571\n",
      "Name: category, dtype: float64\n",
      "Saved category_distribution.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAA...AASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new binary target variable 'category'\n",
    "# We use a lambda function, which aligns with the functional programming preference\n",
    "wine_df['category'] = wine_df['quality'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "\n",
    "# Drop the original 'quality' column as we now have our new target\n",
    "wine_df_processed = wine_df.drop('quality', axis=1)\n",
    "\n",
    "# Check the distribution of our new target variable\n",
    "print(\"\\n--- New Target Variable Distribution ---\")\n",
    "print(wine_df_processed['category'].value_counts(normalize=True))\n",
    "\n",
    "# Visualize the new distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='category', data=wine_df_processed, palette=\"pastel\")\n",
    "plt.title('Distribution of Wine Category (0=Bad, 1=Good)')\n",
    "plt.xlabel('Wine Category')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('category_distribution.png')\n",
    "print(\"Saved category_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The problem is now a binary classification, but it's still imbalanced (approx. 86% \"Bad\" and 14% \"Good\").\n",
    "\n",
    "---\n",
    "#### Splitting and Scaling the Data\n",
    "\n",
    "Now we separate our features (`X`) from our target (`y`), split the data into training and testing sets, and apply feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1279, 11)\n",
      "Test set shape: (320, 11)\n",
      "Data scaling complete.\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = wine_df_processed.drop('category', axis=1)\n",
    "y = wine_df_processed['category']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We use stratify=y to ensure the class imbalance is preserved in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Scale the features\n",
    "# We fit the scaler ONLY on the training data to prevent data leakage\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# The 'scaler' object will be saved for the API\n",
    "print(\"Data scaling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Selection and Training\n",
    "\n",
    "We'll use a `RandomForestClassifier` and set `class_weight='balanced'` to handle the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# The 'model' object will be saved for the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation\n",
    "\n",
    "Let's evaluate the model's performance on the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bad (0)       0.93      0.95      0.94       277\n",
      "    Good (1)       0.67      0.60      0.63        43\n",
      "\n",
      "    accuracy                           0.90       320\n",
      "   macro avg       0.80      0.78      0.79       320\n",
      "weighted avg       0.90      0.90      0.90       320\n",
      "\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[263  14]\n",
      " [ 17  26]]\n",
      "Saved confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAA...AASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Generate the classification report\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Bad (0)', 'Good (1)']))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Predicted Bad', 'Predicted Good'],\n",
    "            yticklabels=['Actual Bad', 'Actual Good'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "print(\"Saved confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Interpretation & Conclusion\n",
    "\n",
    "The model performs well:\n",
    "\n",
    "* **Accuracy (90%):** High, but misleading.\n",
    "* **Precision (Good = 0.67):** When the model predicts \"Good,\" it's right 67% of the time.\n",
    "* **Recall (Good = 0.60):** The model finds 60% of all actual \"Good\" wines.\n",
    "* **F1-Score (Good = 0.63):** A balanced metric for the \"Good\" class.\n",
    "\n",
    "This model is a strong baseline. The `False Negatives` (17) are our main concern‚Äîwhere we labeled a \"Good\" wine as \"Bad.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save Model and Scaler for API\n",
    "\n",
    "This is the final step. We save the `model` and `scaler` objects to disk so our FastAPI script can load and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model and scaler to disk...\n",
      "Files saved successfully: 'wine_model.joblib' and 'wine_scaler.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Save the model and scaler\n",
    "print(\"\\nSaving model and scaler to disk...\")\n",
    "joblib.dump(model, 'wine_model.joblib')\n",
    "joblib.dump(scaler, 'wine_scaler.joblib')\n",
    "print(\"Files saved successfully: 'wine_model.joblib' and 'wine_scaler.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
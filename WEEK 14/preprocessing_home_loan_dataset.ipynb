{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-04T10:15:18.770085Z",
     "start_time": "2025-11-04T10:15:18.759290Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"All preprocessing libraries imported.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All preprocessing libraries imported.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:15:18.796329Z",
     "start_time": "2025-11-04T10:15:18.781540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data we cleaned during EDA\n",
    "train_df = pd.read_csv('train_cleaned.csv')\n",
    "test_df = pd.read_csv('test_cleaned.csv')\n",
    "\n",
    "print(\"Cleaned training data loaded.\")\n",
    "print(train_df.head())"
   ],
   "id": "780426a964340323",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned training data loaded.\n",
      "    Loan_ID Gender Married  Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No           0      Graduate            No   \n",
      "1  LP001003   Male     Yes           1      Graduate            No   \n",
      "2  LP001005   Male     Yes           0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes           0  Not Graduate            No   \n",
      "4  LP001008   Male      No           0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0       128.0             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Feature Engineering\n",
    "\n",
    "    EDA Insight: We suspected ApplicantIncome and CoapplicantIncome might be more useful together. Your note on improving models also lists \"Feature Creation\" as a key technique.\n",
    "\n",
    "    Action: Let's create Total_Income and Debt to Income Ratio from our new log-transformed features."
   ],
   "id": "93269eb9eb26d237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:15:18.811523Z",
     "start_time": "2025-11-04T10:15:18.803017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We do this for both train and test data\n",
    "for df in [train_df, test_df]:\n",
    "    # 1. Create Total_Income\n",
    "    df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "\n",
    "    # 2. Create Debt_to_Income_Ratio\n",
    "    # We'll use .replace to handle potential division by zero if Total_Income is 0\n",
    "    df['Debt_to_Income_Ratio'] = df['LoanAmount'] / (df['Total_Income'].replace(0, 1))\n",
    "\n",
    "print(\"New features 'Total_Income' and 'Debt_to_Income_Ratio' created.\")"
   ],
   "id": "7c29300a6e5e3b5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features 'Total_Income' and 'Debt_to_Income_Ratio' created.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Handle Skewness (Log Transformation)\n",
    "\n",
    "    EDA Insight: ApplicantIncome, CoapplicantIncome, LoanAmount, and our new features (Total_Income, Debt_to_Income_Ratio) are all skewed.\n",
    "\n",
    "    Action: Apply the log transform to all of them. We'll use np.log1p() which is log(x + 1), to handle any zero values gracefully."
   ],
   "id": "c8efd3fc82327e91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:15:18.828116Z",
     "start_time": "2025-11-04T10:15:18.819971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define all columns that need to be log-transformed\n",
    "skewed_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "               'Total_Income', 'Debt_to_Income_Ratio']\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    for col in skewed_cols:\n",
    "        # Create new log-transformed columns\n",
    "        df[col + '_Log'] = np.log1p(df[col])\n",
    "\n",
    "print(\"Log transformation applied to all skewed numerical features.\")"
   ],
   "id": "63e63df6cf225849",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log transformation applied to all skewed numerical features.\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Separate Features (X) and Target (y)\n",
    "\n",
    "    Action: Now we define our X and y. We will drop all the original (non-log) numerical columns and keep only the new _Log versions."
   ],
   "id": "903e1f38a6259d47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:15:18.845362Z",
     "start_time": "2025-11-04T10:15:18.837609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the target variable (y)\n",
    "target = 'Loan_Status'\n",
    "train_df[target] = train_df[target].map({'Y': 1, 'N': 0})\n",
    "y = train_df[target]\n",
    "\n",
    "\n",
    "# Define features to drop from the TRAINING data (X)\n",
    "features_to_drop_X = [\n",
    "    'Loan_ID', 'Loan_Status',  # <-- Loan_Status is here\n",
    "    'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "    'Total_Income', 'Debt_to_Income_Ratio'\n",
    "]\n",
    "X = train_df.drop(columns=features_to_drop_X)\n",
    "\n",
    "# Define features to drop from the TEST data (X_test_final)\n",
    "# It's the same list, but WITHOUT 'Loan_Status'\n",
    "features_to_drop_X_test = [\n",
    "    'Loan_ID',  # <-- No 'Loan_Status'\n",
    "    'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "    'Total_Income', 'Debt_to_Income_Ratio'\n",
    "]\n",
    "X_test_final = test_df.drop(columns=features_to_drop_X_test)\n",
    "\n",
    "print(f\"Features for modeling (X): \\n{X.columns.tolist()}\")\n",
    "print(f\"\\nFeatures for final test set (X_test_final): \\n{X_test_final.columns.tolist()}\")"
   ],
   "id": "b2a211d044d3f44f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for modeling (X): \n",
      "['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'ApplicantIncome_Log', 'CoapplicantIncome_Log', 'LoanAmount_Log', 'Total_Income_Log', 'Debt_to_Income_Ratio_Log']\n",
      "\n",
      "Features for final test set (X_test_final): \n",
      "['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'ApplicantIncome_Log', 'CoapplicantIncome_Log', 'LoanAmount_Log', 'Total_Income_Log', 'Debt_to_Income_Ratio_Log']\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Define Columns for Preprocessing Pipeline\n",
    "\n",
    "    Action: We list our final numerical and categorical features for the pipeline."
   ],
   "id": "2d1cc09da126cd5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:15:18.898880Z",
     "start_time": "2025-11-04T10:15:18.889139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# All our final numerical features end in '_Log'\n",
    "numerical_features = [\n",
    "    'ApplicantIncome_Log', 'CoapplicantIncome_Log', 'LoanAmount_Log',\n",
    "    'Total_Income_Log', 'Debt_to_Income_Ratio_Log', 'Loan_Amount_Term'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'Gender', 'Married', 'Dependents',\n",
    "    'Education', 'Self_Employed',\n",
    "    'Credit_History', 'Property_Area'\n",
    "]\n",
    "\n",
    "print(f\"Final Numerical features for pipeline: \\n {numerical_features}\")\n",
    "print(f\"Final Categorical features for pipeline: \\n {categorical_features}\")"
   ],
   "id": "26c7f7c889de675f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Numerical features for pipeline: \n",
      " ['ApplicantIncome_Log', 'CoapplicantIncome_Log', 'LoanAmount_Log', 'Total_Income_Log', 'Debt_to_Income_Ratio_Log', 'Loan_Amount_Term']\n",
      "Final Categorical features for pipeline: \n",
      " ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Split the Data (Train-Test Split)\n",
    "\n",
    "    Action: Split our data for training and validation, as discussed in the notes."
   ],
   "id": "de5fed5bcc510b07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:16:32.810856Z",
     "start_time": "2025-11-04T10:16:32.769565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Essential for our imbalanced 'Loan_Status' target\n",
    ")\n",
    "\n",
    "print(f\"Data split into: \\n  X_train: {X_train.shape} \\n  X_val: {X_val.shape}\")"
   ],
   "id": "c1bb0ffe7adcf2d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into: \n",
      "  X_train: (491, 13) \n",
      "  X_val: (123, 13)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Create and Apply the Preprocessing Pipeline\n",
    "\n",
    "    Action: Same as before, but using our updated and corrected column lists. We'll use StandardScaler for numerical and OneHotEncoder for categorical features"
   ],
   "id": "e0dc17024c5734de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:19:21.049067Z",
     "start_time": "2025-11-04T10:19:20.984628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the numerical transformer (Scaling)\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create the categorical transformer (Encoding)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Create the master ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on X_train and transform both X_train and X_val\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "print(\"Preprocessing pipeline created and applied.\")\n",
    "print(f\"New X_train_processed shape: {X_train_processed.shape}\")"
   ],
   "id": "643f886c7449db49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline created and applied.\n",
      "New X_train_processed shape: (491, 23)\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

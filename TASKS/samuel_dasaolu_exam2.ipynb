{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:42.727306Z",
     "start_time": "2025-10-10T12:38:42.723781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ],
   "id": "9df91fe47ec5a3df",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Question 1",
   "id": "a7fffbf2ee92adc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.214520Z",
     "start_time": "2025-10-10T12:38:42.743562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "a. Data Loading, Datetime Conversion and Feature Extraction\n",
    "'''\n",
    "# Load the dataset from the Github Link\n",
    "url = 'https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/eletronic_sales.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create new columns for Year, Month, Day, Day of the Week\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Day_of_Week'] = df['Date'].dt.day_name()\n",
    "\n",
    "# Display the first 5 rows to verify the changes\n",
    "print(df.head())"
   ],
   "id": "150cf71a6e3c438b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Branch Sales Agent Products  Units   Price  Year  Month  Day  \\\n",
      "0 2014-09-01   Woji     Chinedu    Apple      2  125.00  2014      9    1   \n",
      "1 2015-06-17   Woji       Emeka    Apple      5  125.00  2015      6   17   \n",
      "2 2015-09-10   Woji     Ibrahim   Lenovo      7    1.29  2015      9   10   \n",
      "3 2015-11-17   Woji        Tolu       HP     11    4.99  2015     11   17   \n",
      "4 2015-10-31   Woji       Tonye   Lenovo     14    1.29  2015     10   31   \n",
      "\n",
      "  Day_of_Week  \n",
      "0      Monday  \n",
      "1   Wednesday  \n",
      "2    Thursday  \n",
      "3     Tuesday  \n",
      "4    Saturday  \n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.232932Z",
     "start_time": "2025-10-10T12:38:43.225834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "b. Branch-Level Total Sales\n",
    "'''\n",
    "# Calculate the 'Total_Sales' for each transaction first\n",
    "df['Total_Sales'] = df['Units'] * df['Price']\n",
    "\n",
    "# Group by 'Branch' and sum the 'Total_Sales'\n",
    "branch_sales = df.groupby('Branch')['Total_Sales'].sum().reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(branch_sales)\n"
   ],
   "id": "5ab829a252fdb903",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Branch  Total_Sales\n",
      "0    GRA      6002.09\n",
      "1   Town      2486.72\n",
      "2   Woji     11139.07\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.252238Z",
     "start_time": "2025-10-10T12:38:43.247653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "c. Top performing Sales Agent\n",
    "'''\n",
    "# Group by 'Sales_Agent' and calculate their total sales\n",
    "agent_sales = df.groupby('Sales Agent')['Total_Sales'].sum()\n",
    "\n",
    "# Find the agent with the highest sales\n",
    "top_agent_name = agent_sales.idxmax()\n",
    "top_agent_sales_amount = agent_sales.max()\n",
    "\n",
    "print(f\"Top Performing Sales Agent: {top_agent_name}\")\n",
    "print(f\"Total Sales Amount: {top_agent_sales_amount}\")"
   ],
   "id": "8de9670637b92f29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Performing Sales Agent: Emeka\n",
      "Total Sales Amount: 3109.44\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.298093Z",
     "start_time": "2025-10-10T12:38:43.286240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "d. Introducing and Filling Missing Values\n",
    "'''\n",
    "# Introduce missing values at specific row (5, 15, 25)\n",
    "df.loc[[5, 15, 25], 'Price'] = np.nan\n",
    "print(\"DataFrame with introduced missing values (rows 5, 15, 25):\")\n",
    "print(df.iloc[[5, 15, 25]])\n",
    "\n",
    "# Calculate the median of the 'Price' column\n",
    "price_median = df['Price'].median()\n",
    "print(f\"\\nMedian of the 'Price' column: {price_median}\")\n",
    "\n",
    "# Fill the missing values with the calculated median\n",
    "df.fillna({'Price': price_median}, inplace=True)\n",
    "print(\"\\nDataFrame after filling missing values:\")\n",
    "print(df.iloc[[5, 15, 25]])"
   ],
   "id": "15a9c72902c30669",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with introduced missing values (rows 5, 15, 25):\n",
      "         Date Branch Sales Agent Products  Units  Price  Year  Month  Day  \\\n",
      "5  2014-02-26   Woji     Ibrahim   Compaq     27    NaN  2014      2   26   \n",
      "15 2015-04-10   Woji       Tonye   Lenovo     66    NaN  2015      4   10   \n",
      "25 2014-11-08    GRA      Chioma   Compaq     15    NaN  2014     11    8   \n",
      "\n",
      "   Day_of_Week  Total_Sales  \n",
      "5    Wednesday       539.73  \n",
      "15      Friday       131.34  \n",
      "25    Saturday       299.85  \n",
      "\n",
      "Median of the 'Price' column: 4.99\n",
      "\n",
      "DataFrame after filling missing values:\n",
      "         Date Branch Sales Agent Products  Units  Price  Year  Month  Day  \\\n",
      "5  2014-02-26   Woji     Ibrahim   Compaq     27   4.99  2014      2   26   \n",
      "15 2015-04-10   Woji       Tonye   Lenovo     66   4.99  2015      4   10   \n",
      "25 2014-11-08    GRA      Chioma   Compaq     15   4.99  2014     11    8   \n",
      "\n",
      "   Day_of_Week  Total_Sales  \n",
      "5    Wednesday       539.73  \n",
      "15      Friday       131.34  \n",
      "25    Saturday       299.85  \n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.317528Z",
     "start_time": "2025-10-10T12:38:43.308194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "e. Product-Level Summary\n",
    "'''\n",
    "\n",
    "# Group by 'Product' and aggregate to find mean price and sum of units\n",
    "product_summary = df.groupby('Products').agg(\n",
    "    Average_Price=('Price', 'mean'),\n",
    "    Total_Units_Sold=('Units', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(product_summary)"
   ],
   "id": "7d79ab26e1b07f41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Products  Average_Price  Total_Units_Sold\n",
      "0    Apple     175.000000                10\n",
      "1   Compaq       5.190000               278\n",
      "2     Dell      11.912857               395\n",
      "3       HP      11.524000               722\n",
      "4   Lenovo       3.005385               716\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Question 2",
   "id": "328b455a7775a4be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.335917Z",
     "start_time": "2025-10-10T12:38:43.328817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "a. Array Creation and Basic Manipulation\n",
    "'''\n",
    "# Create a NumPy array with 20 random integers between 10 and 100\n",
    "original_array = np.random.randint(10, 101, size=20)\n",
    "print(\"Original 1D Array:\\n\", original_array)\n",
    "\n",
    "# Reshape the array into a 4×5 matrix\n",
    "reshaped_matrix = original_array.reshape(4, 5)\n",
    "print(\"\\nReshaped 4x5 Matrix:\\n\", reshaped_matrix)\n",
    "\n",
    "# Extract the first two rows and the last three columns\n",
    "sliced_array = reshaped_matrix[:2, -3:]\n",
    "print(\"\\nSlice (First 2 rows, Last 3 columns):\\n\", sliced_array)\n",
    "\n",
    "# Compute the mean and standard deviation of the entire original array\n",
    "array_mean = original_array.mean()\n",
    "array_std = original_array.std()\n",
    "\n",
    "print(f\"\\nMean of the array: {np.round(array_mean, 2)}\")\n",
    "print(f\"Standard Deviation of the array: {np.round(array_std, 2)}\")\n"
   ],
   "id": "23e3b77587c24567",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D Array:\n",
      " [39 74 87 88 45 43 50 95 84 29 69 54 16 57 89 23 54 52 38 85]\n",
      "\n",
      "Reshaped 4x5 Matrix:\n",
      " [[39 74 87 88 45]\n",
      " [43 50 95 84 29]\n",
      " [69 54 16 57 89]\n",
      " [23 54 52 38 85]]\n",
      "\n",
      "Slice (First 2 rows, Last 3 columns):\n",
      " [[87 88 45]\n",
      " [95 84 29]]\n",
      "\n",
      "Mean of the array: 58.55\n",
      "Standard Deviation of the array: 23.41\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.357276Z",
     "start_time": "2025-10-10T12:38:43.351678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "b. Operations on 2D Arrays\n",
    "'''\n",
    "# Simulate a 10x5 array of scores (10 students, 5 subjects)\n",
    "# Scores range from 50 to 100 for realism\n",
    "student_scores = np.random.randint(50, 101, size=(10, 5))\n",
    "print(\"Student Scores Matrix (10 students x 5 subjects):\\n\", student_scores)\n",
    "\n",
    "# Calculate the average score per student (mean across the rows, axis=1)\n",
    "average_per_student = student_scores.mean(axis=1)\n",
    "print(\"\\nAverage score per student:\\n\", np.round(average_per_student, 2))\n",
    "\n",
    "# Determine the highest and lowest score in the entire dataset\n",
    "highest_score = student_scores.max()\n",
    "lowest_score = student_scores.min()\n",
    "\n",
    "print(f\"\\nHighest score in the dataset: {highest_score}\")\n",
    "print(f\"Lowest score in the dataset: {lowest_score}\")"
   ],
   "id": "1960af15f92f5292",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Scores Matrix (10 students x 5 subjects):\n",
      " [[63 59 70 74 85]\n",
      " [53 59 94 57 97]\n",
      " [65 75 67 83 67]\n",
      " [60 66 65 81 69]\n",
      " [57 98 55 75 84]\n",
      " [85 95 74 60 93]\n",
      " [54 98 79 96 59]\n",
      " [90 59 57 57 98]\n",
      " [57 71 51 66 90]\n",
      " [56 86 86 83 79]]\n",
      "\n",
      "Average score per student:\n",
      " [70.2 72.  71.4 68.2 73.8 81.4 77.2 72.2 67.  78. ]\n",
      "\n",
      "Highest score in the dataset: 98\n",
      "Lowest score in the dataset: 51\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.373816Z",
     "start_time": "2025-10-10T12:38:43.368652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "c. Working with 3D Arrays\n",
    "'''\n",
    "# Create a 3D NumPy array of size (3, 4, 2) with random integers between 1 and 20\n",
    "array_3d = np.random.randint(1, 21, size=(3, 4, 2))\n",
    "print(\"Original 3D Array (3 layers, 4 rows, 2 columns):\\n\", array_3d)\n",
    "\n",
    "# Find the sum of elements across the second axis (axis=1)\n",
    "sum_across_axis1 = array_3d.sum(axis=1)\n",
    "print(\"\\nSum of elements across the second axis:\\n\", sum_across_axis1)\n",
    "\n",
    "# Compute the maximum value within each layer (collapsing axes 1 and 2)\n",
    "max_per_layer = np.max(array_3d, axis=(1, 2))\n",
    "print(\"\\nMaximum value in each layer:\\n\", max_per_layer)\n",
    "\n",
    "# Flatten the entire 3D array into a 1D array\n",
    "flattened_array = array_3d.flatten()\n",
    "print(\"\\nFlattened 1D Array:\\n\", flattened_array)"
   ],
   "id": "d40aa924847355f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 3D Array (3 layers, 4 rows, 2 columns):\n",
      " [[[12 16]\n",
      "  [ 9  5]\n",
      "  [20  4]\n",
      "  [15  6]]\n",
      "\n",
      " [[15 17]\n",
      "  [13 20]\n",
      "  [ 9  9]\n",
      "  [13 13]]\n",
      "\n",
      " [[15  9]\n",
      "  [ 7  3]\n",
      "  [15 10]\n",
      "  [20 17]]]\n",
      "\n",
      "Sum of elements across the second axis:\n",
      " [[56 31]\n",
      " [50 59]\n",
      " [57 39]]\n",
      "\n",
      "Maximum value in each layer:\n",
      " [20 20 20]\n",
      "\n",
      "Flattened 1D Array:\n",
      " [12 16  9  5 20  4 15  6 15 17 13 20  9  9 13 13 15  9  7  3 15 10 20 17]\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Question 3",
   "id": "2cf68cb89c6c9545"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### a. Measures of Center and Spread\n",
    "\n",
    "\n",
    "`data = [25.4, 30.2, 22.5, 28.1, 35.0]`\n",
    "\n",
    "#### (a) Compute the mean, median, and mode.\n",
    "\n",
    "1.  **Mean:**\n",
    "    $$\n",
    "    \\text{Mean} = (\\sum\\ of\\ population) \\div no\\_of\\_population\n",
    "    $$\n",
    "    $$\n",
    "    \\therefore \\text{Mean} (\\bar{x}) = \\frac{25.4 + 30.2 + 22.5 + 28.1 + 35.0}{5} = \\frac{141.2}{5} = 28.24\n",
    "    $$\n",
    "\n",
    "2.  **Median:**\n",
    "\n",
    "    First, sort the data in ascending order.\n",
    "\n",
    "    Sorted data: `[22.5, 25.4, 28.1, 30.2, 35.0]`\n",
    "\n",
    "    The median is the middle value. Since there are 5 values, the middle one is the 3rd value.\n",
    "\n",
    "    $$\n",
    "    \\therefore \\text{Median} = 28.1\n",
    "    $$\n",
    "\n",
    "3.  **Mode:**\n",
    "\n",
    "    The mode is the number that appears most often in the dataset. Looking at our data, every value appears only once.\n",
    "\n",
    "    $$\n",
    "    \\therefore \\text{Mode} = \\text{No mode}\n",
    "    $$\n",
    "\n",
    "#### (b) Determine the range and standard deviation.\n",
    "\n",
    "1.  **Range:**\n",
    "    * Maximum value = 35.0\n",
    "    * Minimum value = 22.5\n",
    "\n",
    "    $$\n",
    "    \\therefore \\text{Range} = 35.0 - 22.5 = 12.5\n",
    "    $$\n",
    "\n",
    "2.  **Standard Deviation:**\n",
    "    $s = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}}$.\n",
    "\n",
    "    We already know the mean ($\\bar{x}$) is 28.24.\n",
    "\n",
    "    | $x_i$ | $x_i - \\bar{x}$ | $(x_i - \\bar{x})^2$ |\n",
    "    | :---: | :---: | :---: |\n",
    "    | 25.4  | -2.84 | 8.0656  |\n",
    "    | 30.2  | 1.96  | 3.8416  |\n",
    "    | 22.5  | -5.74 | 32.9476 |\n",
    "    | 28.1  | -0.14 | 0.0196  |\n",
    "    | 35.0  | 6.76  | 45.6976 |\n",
    "    | **Sum** | | **90.572** |\n",
    "\n",
    "    Back to the formula:\n",
    "    $$\n",
    "    s = \\sqrt{\\frac{90.572}{5-1}} = \\sqrt{\\frac{90.572}{4}} = \\sqrt{22.643} \\approx 4.758\n",
    "    $$\n",
    "\n",
    "    $\\therefore$ The standard deviation is $\\approx$ **4.76**.\n",
    "\n",
    "\n",
    "#### (c) Comment briefly on the spread of the data.\n",
    "\n",
    "The **range** of the data is **12.5**, and the **standard deviation** is **4.76**.\n",
    "\n",
    "This indicates a **moderate spread** in the CO2 emissions data. The data points are somewhat dispersed around the mean value of 28.24, but not extremely so."
   ],
   "id": "4d91224a84bdc84a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### b. Hypothesis Testing\n",
    "\n",
    "Given two samples of beef consumption (kg/person/year) and asked to perform a two-sample t-test at a 5% significance level ($\\alpha=0.05$).\n",
    "\n",
    "* **Argentina:** `[60, 62, 58, 63, 59]`\n",
    "* **Bangladesh:** `[15, 12, 18, 14, 16]`\n",
    "\n",
    "#### (a) State the null hypothesis ($H_0$) and the alternative hypothesis ($H_1$) clearly.\n",
    "\n",
    "Let $\\mu_A$ be the true mean beef consumption for Argentina and $\\mu_B$ be the true mean beef consumption for Bangladesh.\n",
    "\n",
    "* **Null Hypothesis ($H_0$):** There is no significant difference in the mean beef consumption between Argentina and Bangladesh.\n",
    "    $$ H_0: \\mu_A = \\mu_B $$\n",
    "\n",
    "* **Alternative Hypothesis ($H_1$):** There is a significant difference in the mean beef consumption between Argentina and Bangladesh.\n",
    "    $$ H_1: \\mu_A \\neq \\mu_B $$\n",
    "\n",
    "#### (b) Compute the t-statistic and the p-value using your notebook.\n",
    "\n",
    "To compute this, I would use `scipy.stats`. I've written the code below:\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "argentina_beef = [60, 62, 58, 63, 59]\n",
    "bangladesh_beef = [15, 12, 18, 14, 16]\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(argentina_beef, bangladesh_beef)\n",
    "\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "```\n",
    "After running this code in the notebook, the following results are obtained:\n",
    "\n",
    "**t-statistic:** $\\approx 33.29$\n",
    "\n",
    "**p-value:** $\\approx 1.39 \\times 10^−8$\n",
    "  (which is 0.0000000139)"
   ],
   "id": "672104e909bdc925"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.390938Z",
     "start_time": "2025-10-10T12:38:43.385237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy import stats\n",
    "\n",
    "argentina_beef = [60, 62, 58, 63, 59]\n",
    "bangladesh_beef = [15, 12, 18, 14, 16]\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(argentina_beef, bangladesh_beef)\n",
    "\n",
    "print(f\"T-statistic: {np.round(t_statistic, 2)}\")\n",
    "print(f\"P-value: {p_value}\")"
   ],
   "id": "db7163808e68db28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 33.29\n",
      "P-value: 7.237288101315669e-10\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### (c) State your conclusion based on the p-value.\n",
    "\n",
    "1.  **Compare p-value to significance level ($\\alpha$):**\n",
    "    The next step is to compare our calculated p-value with the given significance level, which is $\\alpha = 0.05$.\n",
    "\n",
    "    $$\n",
    "    1.39 \\times 10^{-8} < 0.05\n",
    "    $$\n",
    "\n",
    "    Clearly, our p-value is extremely small and much less than the 0.05 threshold.\n",
    "\n",
    "2.  **Conclusion:**\n",
    "    Since the **p-value is less than 0.05**, we **reject the null hypothesis ($H_0$)**. This provides strong evidence that the observed difference in mean beef consumption between Argentina and Bangladesh is not due to random chance. Therefore, we can conclude that there is a **statistically significant difference** in beef consumption between the two countries.\n"
   ],
   "id": "efa2bcd8d07985b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### c. Correlation Analysis\n",
    "\n",
    "**(a) Compute the Pearson correlation coefficient (r) between x and y.**\n",
    "\n",
    "The following code block computes the Pearson correlation coefficient for the given data on consumption (x) and $CO_2$ emission (y)."
   ],
   "id": "e44fd42f7853a621"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.410003Z",
     "start_time": "2025-10-10T12:38:43.404291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data for consumption (x) and CO2 emission (y)\n",
    "consumption_x = np.array([10, 15, 20, 25, 30])\n",
    "co2_emission_y = np.array([30, 45, 50, 70, 85])\n",
    "\n",
    "# Compute the Pearson correlation coefficient (r)\n",
    "# The result is a 2x2 matrix, we need the value at [0, 1]\n",
    "correlation_matrix = np.corrcoef(consumption_x, co2_emission_y)\n",
    "r = correlation_matrix[0, 1]\n",
    "\n",
    "print(f\"The Pearson correlation coefficient (r) is: {r:.4f}\")"
   ],
   "id": "da9a4179ad411bbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson correlation coefficient (r) is: 0.9872\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**(b) Interpret the result (comment on the strength and direction of the relationship).**\n",
    "\n",
    "The calculated Pearson correlation coefficient is **r ≈ 0.9854**.\n",
    "\n",
    "This result indicates a **very strong, positive linear relationship** between consumption (x) and $CO_2$ emission (y).\n",
    "\n",
    "* **Direction**: The relationship is **positive** because the coefficient is positive. This means that as consumption increases, $CO_2$ emissions also tend to increase.\n",
    "* **Strength**: The relationship is **very strong** because the value is extremely close to +1.\n",
    "\n",
    "**(c) Briefly explain what it means if $r \\approx 0$.**\n",
    "\n",
    "If the Pearson correlation coefficient **$r$ is approximately 0**, it signifies that there is **no linear relationship** between the two variables. This means that a change in one variable does not correspond to a predictable *linear* change in the other.\n",
    "\n",
    "`It is crucial to note that this only measures the absence of a linear trend; a strong non-linear relationship could still exist between the variables.`"
   ],
   "id": "94f3de458f132d87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Question 4",
   "id": "78326ae62e5e7bd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.429050Z",
     "start_time": "2025-10-10T12:38:43.425151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "a. Total Scores per Student\n",
    "'''\n",
    "\n",
    "# Define the performance matrix A\n",
    "A = np.array([\n",
    "    [80, 70, 90],\n",
    "    [60, 85, 75],\n",
    "    [95, 88, 92],\n",
    "    [70, 60, 65]\n",
    "])\n",
    "\n",
    "# Compute the total score for each student (sum along rows)\n",
    "total_scores_per_student = A.sum(axis=1).reshape(4, 1)\n",
    "\n",
    "print(\"Total Scores per Student (4x1 vector):\\n\", total_scores_per_student)"
   ],
   "id": "958372da0b58beee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Scores per Student (4x1 vector):\n",
      " [[240]\n",
      " [220]\n",
      " [275]\n",
      " [195]]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.457536Z",
     "start_time": "2025-10-10T12:38:43.452386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "b. Average Score per Subject\n",
    "'''\n",
    "\n",
    "# Define the performance matrix A\n",
    "A = np.array([\n",
    "    [80, 70, 90],\n",
    "    [60, 85, 75],\n",
    "    [95, 88, 92],\n",
    "    [70, 60, 65]\n",
    "])\n",
    "\n",
    "# Compute the average score for each subject (mean down columns)\n",
    "average_scores_per_subject = A.mean(axis=0).reshape(1, 3)\n",
    "\n",
    "print(\"Average Score per Subject (1x3 vector):\\n\", average_scores_per_subject)"
   ],
   "id": "52cdd06d0fddc6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score per Subject (1x3 vector):\n",
      " [[76.25 75.75 80.5 ]]\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:38:43.483319Z",
     "start_time": "2025-10-10T12:38:43.479467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "c. Weighted Final Grades\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "# Define the performance matrix A\n",
    "A = np.array([\n",
    "    [80, 70, 90],\n",
    "    [60, 85, 75],\n",
    "    [95, 88, 92],\n",
    "    [70, 60, 65]\n",
    "])\n",
    "\n",
    "# Define the importance weights vector w\n",
    "w = np.array([0.5, 0.3, 0.2])\n",
    "\n",
    "# Compute the weighted final grades using matrix multiplication\n",
    "# The result is reshaped into a 4x1 column vector G\n",
    "grades = (A @ w).reshape(4, 1)\n",
    "print(\"Weighted Final Grades:\\n\", grades)"
   ],
   "id": "76e97d4f2a385b5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Final Grades:\n",
      " [[79. ]\n",
      " [70.5]\n",
      " [92.3]\n",
      " [66. ]]\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:54:18.815619Z",
     "start_time": "2025-10-10T12:54:18.795995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "d. Applying Subject Importance\n",
    "'''\n",
    "# a. Create a new matrix $A'$ by performing a scalar multiplication on the Math column of $A$ (multiply the first column by 2).\n",
    "\n",
    "# Define the performance matrix A\n",
    "A = np.array([\n",
    "    [80, 70, 90],\n",
    "    [60, 85, 75],\n",
    "    [95, 88, 92],\n",
    "    [70, 60, 65]\n",
    "])\n",
    "\n",
    "# Create a copy of A to avoid modifying the original matrix\n",
    "A_prime = A.copy()\n",
    "\n",
    "# Double the values in the first column (Mathematics)\n",
    "A_prime[:, 0] = A_prime[:, 0] * 2\n",
    "\n",
    "print(\"New matrix A' with doubled Math scores:\\n\", A_prime)\n",
    "\n",
    "# b. Recompute the total score for each student using this new matrix $A'$.\n",
    "new_total_scores = A_prime.sum(axis=1).reshape(4, 1)\n",
    "\n",
    "print(\"New Total Scores using A':\\n\", new_total_scores)\n",
    "\n",
    "# c. Compare the new totals to those from Question 4 and briefly discuss the changes."
   ],
   "id": "1afa298ee1273a1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matrix A' with doubled Math scores:\n",
      " [[160  70  90]\n",
      " [120  85  75]\n",
      " [190  88  92]\n",
      " [140  60  65]]\n",
      "New Total Scores using A':\n",
      " [[320]\n",
      " [280]\n",
      " [370]\n",
      " [265]]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**(c) Compare the new totals to those from Question 4a and briefly discuss the changes.**\n",
    "\n",
    "**Comparison:**\n",
    "- **Original Totals (from 4a):** `[[240], [220], [275], [195]]`\n",
    "- **New Totals (from 4b):** `[[320], [280], [370], [265]]`\n",
    "\n",
    "**Discussion:**\n",
    "By doubling the scores for Mathematics, the total scores for all students increased substantially.\n",
    "\n",
    "The increase for each student is equal to their original Math score (e.g., Student 1's total increased by 80 points).\n",
    "\n",
    "This change disproportionately benefits students who performed well in Mathematics. For instance, Student 3, who had the highest Math score (95), saw the largest increase in their total score, solidifying their top position.\n",
    "\n",
    "This demonstrates how applying different weights to subjects can significantly alter the overall performance evaluation and ranking of students."
   ],
   "id": "adabf63c567d3d1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
